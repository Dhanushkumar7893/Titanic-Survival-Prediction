 ğŸš¢ Titanic Survival Prediction
This project aims to predict the survival of passengers aboard the Titanic using machine learning techniques. By analyzing the dataset, we build a model to determine survival probability based on passenger details such as age, gender, class, and fare.

ğŸ“Œ Project Overview
The Titanic dataset is one of the most famous datasets in machine learning and is often used for binary classification problems. The goal is to predict whether a passenger survived the disaster based on given features.

ğŸ“‚ Project Structure
mathematica

ğŸ“‚ Titanic-Survival-Prediction
â”‚â”€â”€ ğŸ“„ README.md                 â† Project Documentation
â”‚â”€â”€ ğŸ“„ Titanic_Data_Preprocessing.ipynb  â† Data Cleaning & Preprocessing
â”‚â”€â”€ ğŸ“„ Titanic_Model_Training.ipynb      â† Model Selection & Training
â”‚â”€â”€ ğŸ“„ Titanic_Predictions.ipynb         â† Final Predictions
â”‚â”€â”€ ğŸ“„ requirements.txt         â† Required Python Libraries
â”‚â”€â”€ ğŸ“‚ dataset                  â† Dataset Folder
â”‚     â”œâ”€â”€ titanic_train.csv      â† Training Dataset
â”‚     â”œâ”€â”€ titanic_test.csv       â† Test Dataset
â”‚â”€â”€ ğŸ“‚ models                   â† Saved Model Folder
â”‚     â”œâ”€â”€ best_model.pkl         â† Trained Model File

ğŸ”¹ Dataset
Source: Kaggle Titanic Dataset
Columns Used:
PassengerId: Unique ID of passenger
Survived: 0 = No, 1 = Yes (Target Variable)
Pclass: Passenger class (1st, 2nd, 3rd)
Name, Sex, Age: Passenger details
SibSp, Parch: Number of siblings/spouses and parents/children aboard
Ticket, Fare: Ticket number and fare paid
Cabin, Embarked: Cabin number and port of embarkation

ğŸš€ Installation & Setup
1ï¸âƒ£ Clone the Repository
bash
Copy
Edit
git clone https://github.com/Dhanushkumar7893/Titanic-Survival-Prediction.git
cd Titanic-Survival-Prediction

2ï¸âƒ£ Install Dependencies
bash
Copy
Edit
pip install -r requirements.txt

3ï¸âƒ£ Run Jupyter Notebook
bash
Copy
Edit
jupyter notebook
Open the .ipynb files in Jupyter Notebook and execute the code step by step.

ğŸ† Machine Learning Pipeline
Data Preprocessing

Handle missing values
Encode categorical variables
Feature scaling
Model Training

Tried multiple models (Logistic Regression, Random Forest, XGBoost)
Selected the best model based on accuracy and precision
Prediction & Evaluation

Evaluated using accuracy, precision, recall, F1-score
Saved the best-performing model as best_model.pkl

ğŸ“Š Model Performance
Model	Accuracy
Logistic Regression	78.5%
Random Forest	83.2%
XGBoost	85.1%

âœ¨ Future Improvements
Improve feature engineering
Hyperparameter tuning for better accuracy
Deploy as a web application using Flask

ğŸ“œ License
This project is open-source and available under the MIT License.

ğŸ™Œ Acknowledgments
Kaggle Titanic Dataset
Scikit-Learn Documentation
