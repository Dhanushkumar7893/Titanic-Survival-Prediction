{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d33dc83b-923e-411f-bf52-a83695b5efac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\dhanu\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\dhanu\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dhanu\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\dhanu\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dhanu\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dhanu\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dhanu\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dhanu\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dhanu\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dhanu\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dhanu\\lib\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dhanu\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dhanu\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dhanu\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dhanu\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dhanu\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dhanu\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dhanu\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dhanu\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy matplotlib seaborn scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b35a337c-63a0-4345-8bc3-a27ce185d3ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1104305986.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    python.exe -m pip install --upgrade pip\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python.exe -m pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c0124-e192-455c-bfd2-7d8cfbf520d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # For data handling\n",
    "import numpy as np  # For numerical operations\n",
    "import matplotlib.pyplot as plt  # For visualization\n",
    "import seaborn as sns  # For better-looking plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f1ca7d-d283-458f-9d8d-1bdd9f0c27cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "train_data = pd.read_csv(\"/mnt/data/train.csv\")\n",
    "\n",
    "# Load the testing dataset\n",
    "test_data = pd.read_csv(\"/mnt/data/tested.csv\")\n",
    "\n",
    "# Display the first 5 rows of the training dataset\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e799a6-2527-46e6-a780-d1417d8576fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c8d082-4ffb-41fa-b494-accb0fc8d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the training dataset\n",
    "train_data = pd.read_csv(\"./train.csv\")\n",
    "\n",
    "# Load the testing dataset\n",
    "test_data = pd.read_csv(\"C:/titanic_project/tested.csv\")\n",
    "\n",
    "# Display the first 5 rows of the training dataset\n",
    "print(train_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa0c5e-f9a4-48de-a5c4-d357839a03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(train_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc343b87-7670-498e-a607-e1b03768b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing Age values with the median age\n",
    "train_data[\"Age\"].fillna(train_data[\"Age\"].median(), inplace=True)\n",
    "\n",
    "# Drop the Cabin column\n",
    "train_data.drop(columns=[\"Cabin\"], inplace=True)\n",
    "\n",
    "# Fill missing Embarked values with the most common value\n",
    "train_data[\"Embarked\"].fillna(train_data[\"Embarked\"].mode()[0], inplace=True)\n",
    "\n",
    "# Check if there are any missing values left\n",
    "print(train_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d50254-29b9-4ecb-8083-65162154fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing Age values with the median age\n",
    "train_data[\"Age\"] = train_data[\"Age\"].fillna(train_data[\"Age\"].median())\n",
    "\n",
    "# Drop the Cabin column\n",
    "train_data = train_data.drop(columns=[\"Cabin\"])\n",
    "\n",
    "# Fill missing Embarked values with the most common value\n",
    "train_data[\"Embarked\"] = train_data[\"Embarked\"].fillna(train_data[\"Embarked\"].mode()[0])\n",
    "\n",
    "# Check again for missing values\n",
    "print(train_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7274fa-3270-4811-b1d7-764c621f3065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Cabin column (if it exists)\n",
    "train_data = train_data.drop(columns=[\"Cabin\"], errors='ignore')\n",
    "\n",
    "# Fill missing Age values with the median age\n",
    "train_data[\"Age\"] = train_data[\"Age\"].fillna(train_data[\"Age\"].median())\n",
    "\n",
    "# Fill missing Embarked values with the most common value\n",
    "train_data[\"Embarked\"] = train_data[\"Embarked\"].fillna(train_data[\"Embarked\"].mode()[0])\n",
    "\n",
    "# Check for missing values again\n",
    "print(train_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa3286-bbcf-4445-ba3a-ba4ac36bf03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Sex' column to numerical (0 for male, 1 for female)\n",
    "train_data[\"Sex\"] = train_data[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "# Convert 'Embarked' column using one-hot encoding\n",
    "train_data = pd.get_dummies(train_data, columns=[\"Embarked\"], drop_first=True)\n",
    "\n",
    "# Display the first few rows to check the changes\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837375fa-52ca-4e52-8876-ddc4b75cb36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "train_data = train_data.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\"])\n",
    "\n",
    "# Convert Embarked_Q and Embarked_S to integers (0/1)\n",
    "train_data[\"Embarked_Q\"] = train_data[\"Embarked_Q\"].astype(int)\n",
    "train_data[\"Embarked_S\"] = train_data[\"Embarked_S\"].astype(int)\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = train_data.drop(columns=[\"Survived\"])  # Features\n",
    "y = train_data[\"Survived\"]  # Target\n",
    "\n",
    "# Train-test split (80% training, 20% testing)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shapes of the sets\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751ce75-792a-4d62-9bb7-53685f87cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train (fit) the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc77c8-2ef9-4595-8245-f08b807a0a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=500)  # Increase iterations from default (100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc12a2-cb0d-4cec-85ca-e68864a74868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform test data (use same scaler)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the Logistic Regression model with scaled data\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24f111e-e2a3-477f-be56-5ffdbb756298",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before Scaling:\\n\", X_train[:5])  # Show first 5 rows (original)\n",
    "print(\"\\nAfter Scaling:\\n\", X_train_scaled[:5])  # Show first 5 rows (scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded0abd-c4f2-412c-b314-edfe556f79d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train the model with scaled data\n",
    "model = LogisticRegression(max_iter=1000, solver='lbfgs', verbose=1)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ed1b8-1501-47dc-ada9-8d40c747b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daf6c9d-4138-4e08-80a7-d3163cc85276",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c100a49-8bb2-44da-8c62-566842396506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the model with 500 trees\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79d0812-3f89-42c3-b55d-7f5122910a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=500, max_depth=10, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734106e-dc85-43f4-a0ba-ef50d21cd372",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_model.feature_importances_\n",
    "for feature, importance in zip(X_train.columns, importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8894d249-2c21-416c-8d0b-4ae721a684a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.fit(X_train, y_train)  # Train the model\n",
    "\n",
    "importances = rf_model.feature_importances_\n",
    "for feature, importance in zip(X_train.columns, importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2547802d-ebf6-4a95-8860-f1f8c73fc26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate on test data\n",
    "best_rf = grid_search.best_estimator_\n",
    "test_accuracy = best_rf.score(X_test, y_test)\n",
    "print(\"Best Random Forest Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4c57f-2c35-4655-a585-b5cc39503994",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_rf, 'titanic_survival_model.pkl')\n",
    "\n",
    "# Load and use the model\n",
    "loaded_model = joblib.load('titanic_survival_model.pkl')\n",
    "predictions = loaded_model.predict(X_test)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5d9d9d-bf49-405d-9a41-5eb9cab1e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_distributions=param_grid, n_iter=20, cv=5, n_jobs=-1, verbose=2, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e720178f-7aa6-4ef1-9611-98934f1853b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(2)  # Pause for 2 seconds to allow output to display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc53f9e-bbe4-42d0-be5f-ae3f95ce8f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_distributions=param_grid, n_iter=20, cv=5, n_jobs=-1, verbose=3, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec75791-105d-48c9-b9e1-0a70d8d532a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf)  # Should display: RandomForestClassifier(...)\n",
    "print(param_grid)  # Should show the dictionary of parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0643bb9b-5865-4ae5-8e0c-55996e34d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_distributions=param_grid, n_iter=5, cv=3, n_jobs=-1, verbose=3, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c995c-bacb-496f-b684-cdf713899646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import time  # To check execution time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_distributions=param_grid, n_iter=10, cv=3, n_jobs=-1, verbose=2, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Execution Time:\", time.time() - start_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96af163-b189-4578-ada4-ca795fc9a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=1,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e91c3c-fe6f-4cd9-b1a1-dc8d1412ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = best_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Optimized Random Forest Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894de38a-3a3a-4faf-af40-82b02120a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "feature_importance = best_rf.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(X_train.shape[1]), feature_importance[sorted_idx], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), X_train.columns[sorted_idx], rotation=90)\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.title(\"Feature Importance in Random Forest\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01d40ee-4fc2-4223-b702-44c3a002103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(best_rf, \"titanic_rf_model.pkl\")\n",
    "\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf152a-48e4-4580-a649-dfab8b25f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = joblib.load(\"titanic_rf_model.pkl\")\n",
    "\n",
    "# Make predictions\n",
    "sample_data = X_test.iloc[:5]  # Take 5 samples from the test set\n",
    "predictions = loaded_model.predict(sample_data)\n",
    "\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee78ddd-1a3a-4a47-b4a4-e8ba17fdfa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac070cc8-82f3-451b-bb84-87c4b3b6d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_test = best_rf.predict(X_test)\n",
    "\n",
    "# Convert predictions into a DataFrame for better visualization\n",
    "test_predictions = pd.DataFrame({'PassengerId': test_data['PassengerId'], 'Survived': y_pred_test})\n",
    "\n",
    "# Display the first few predictions\n",
    "print(test_predictions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5099a62-3362-4e04-9141-8a02beb7500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0147c35c-b026-4325-a88c-8747743c768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = best_rf.predict(X_test)\n",
    "test_predictions = pd.DataFrame({'PassengerId': test_data['PassengerId'], 'Survived': y_pred_test})\n",
    "print(test_predictions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d04dea2-09fd-428f-b96e-8159ff96bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_pred_test shape:\", y_pred_test.shape)\n",
    "print(\"test_data shape:\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef66f441-abdb-4932-9d27-cd60233f72cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train features:\", X_train.columns)\n",
    "print(\"Test features:\", X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859411df-0bab-4f41-8111-1e61b2060269",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_processed = test_data[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]]\n",
    "\n",
    "# Apply the same transformations as X_train\n",
    "test_data_processed[\"Sex\"] = test_data_processed[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
    "test_data_processed = pd.get_dummies(test_data_processed, columns=[\"Embarked\"], drop_first=True)\n",
    "\n",
    "# Fill missing values (same method as training data)\n",
    "test_data_processed[\"Age\"].fillna(X_train[\"Age\"].median(), inplace=True)\n",
    "test_data_processed[\"Fare\"].fillna(X_train[\"Fare\"].median(), inplace=True)\n",
    "\n",
    "# Scale the test set (if scaling was used on X_train)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "test_data_processed = scaler.fit_transform(test_data_processed)\n",
    "\n",
    "# Ensure same shape\n",
    "print(test_data_processed.shape)  # Should be (418, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb39c7-e654-4937-9321-8d8d441c303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = best_rf.predict(test_data_processed)\n",
    "test_predictions = pd.DataFrame({'PassengerId': test_data['PassengerId'], 'Survived': y_pred_test})\n",
    "print(test_predictions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de4c99-4d1a-431c-a2ab-4b22bc953726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure test_data_processed has the same columns as X_train\n",
    "missing_cols = set(X_train.columns) - set(test_data_processed.columns)\n",
    "extra_cols = set(test_data_processed.columns) - set(X_train.columns)\n",
    "\n",
    "print(\"Missing columns in test_data:\", missing_cols)\n",
    "print(\"Extra columns in test_data:\", extra_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b7ab5b-7bca-44a7-bf4b-98dff1efa5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert to DataFrame if it's a NumPy array\n",
    "if isinstance(test_data_processed, np.ndarray):\n",
    "    test_data_processed = pd.DataFrame(test_data_processed, columns=X_train.columns)\n",
    "\n",
    "# Now check for missing or extra columns\n",
    "missing_cols = set(X_train.columns) - set(test_data_processed.columns)\n",
    "extra_cols = set(test_data_processed.columns) - set(X_train.columns)\n",
    "\n",
    "print(\"Missing columns in test_data:\", missing_cols)\n",
    "print(\"Extra columns in test_data:\", extra_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a65fd9-f95f-43eb-9a75-bbb40fb31624",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = best_rf.predict(test_data_processed)\n",
    "test_predictions = pd.DataFrame({'PassengerId': test_data['PassengerId'], 'Survived': y_pred_test})\n",
    "print(test_predictions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad5011a-5760-41a3-bbd4-0d72c697a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3372d2-5ec0-4fab-af0f-796ed2fd9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "NameError                                 Traceback (most recent call last)\n",
    "Cell In[2], line 11\n",
    "      8 os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "     10 # Save the trained model\n",
    "---> 11 joblib.dump(best_rf, model_path)\n",
    "     13 print(\"Model saved successfully at:\", model_path)\n",
    "\n",
    "NameError: name 'best_rf' is not defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6525f7b-49e3-4a6b-a7d5-1eeecefe6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a15fc4f-eecc-41d4-a7d8-63c5ba937706",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the path where the model will be saved\n",
    "model_path = \"./models/best_model.pkl\"\n",
    "\n",
    "# Ensure the directory exists (creates the folder if not already created)\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(best_rf, model_path)\n",
    "\n",
    "print(\"Model saved successfully at:\", model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7eb20-f9a1-4321-9fbe-0f59da9c7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = joblib.load(\"./models/best_model.pkl\")\n",
    "\n",
    "# Use it for predictions\n",
    "y_pred = loaded_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a3438e-4501-45ab-9bc6-3f12b016dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the model again\n",
    "best_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Now save it\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "model_path = \"./models/best_model.pkl\"\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "joblib.dump(best_rf, model_path)\n",
    "\n",
    "print(\"Model saved successfully at:\", model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aec66cd-7a17-4ff4-951a-6479da27e83d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
